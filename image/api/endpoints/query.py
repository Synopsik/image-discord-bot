from http.client import responses

from fastapi import APIRouter
from models.Query import Query, AttachmentEnum

router = APIRouter(prefix="/query", tags=["ai"])

@router.get("/")
async def query_get():
    """
    Handles the asynchronous GET request to query data and responds based on the 
    context of the operation. Executes conditional behavior to either return a 
    model-dumped query result or a specified response message.

    :return: The model-dumped representation of the query result if in development 
             mode, otherwise a dictionary containing a specific response message.
    :rtype: dict

    :raises: Logs exceptions during the execution process.
    """
    dev = True
    try:
        if dev:
            _query = Query()
            return _query.model_dump()
        else:
            return {"response": "These are not the droids you are looking for"}
    except Exception as e:
        print(e)

@router.post("/")
async def query_post(user_query: Query):
    """
    Handles POST requests to process user queries and return responses generated
    by an AI assistant. Optionally, it can return the assistant's intermediate 
    thoughts as part of the response.

    This function processes a query object by invoking the `query_llm` function,
    which interacts with the specified LLM to generate a response based on the
    provided query details. The generation can optionally display intermediate
    thought processes, depending on the `show_thoughts` attribute.

    :param query: Instance of the Query class containing the content, LLM, model,
                  and optional settings for thought display.
    :return: The response generated by the LLM based on the given query details.
    :rtype: Depends on the implementation of `query_llm` function.
    """
    message = user_query.query
    show_thoughts = user_query.show_thoughts
    # thoughts, response = assistant.ask(message) implement with api_func
    if show_thoughts:
        return {"reply": "AI response", "thoughts": "AI thoughts"}
    return {"reply": "AI response"}