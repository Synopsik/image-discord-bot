from http.client import responses

from fastapi import APIRouter
from models.Query import Query, AttachmentEnum

router = APIRouter(prefix="/query", tags=["ai"])

@router.get("/")
async def query_get():
    """
    Handles the asynchronous GET request to query data and responds based on the 
    context of the operation. Executes conditional behavior to either return a 
    model-dumped query result or a specified response message.

    :return: The model-dumped representation of the query result if in development 
             mode, otherwise a dictionary containing a specific response message.
    :rtype: dict

    :raises: Logs exceptions during the execution process.
    """
    dev = True
    try:
        if dev:
            _query = Query()
            return _query.model_dump()
        else:
            return {"response": "These are not the droids you are looking for"}
    except Exception as e:
        print(e)

@router.post("/")
async def query_post(user_query: Query):
    """
    Handles POST requests to process user queries and return responses generated
    by an AI assistant. Optionally, it can return the assistant's intermediate 
    thoughts as part of the response.

    :param user_query: Contains the user query and a flag to indicate whether the 
        intermediate thoughts of the AI assistant should be included in the
        response.
    :type user_query: Query
    :return: A dictionary containing the response generated by the AI assistant.
        If the `show_thoughts` flag in `user_query` is True, the dictionary will 
        also include the assistant's intermediate thoughts.
    :rtype: dict
    """
    message = user_query.query
    show_thoughts = user_query.show_thoughts
    # thoughts, response = assistant.ask(message) implement with api_func
    if show_thoughts:
        return {"reply": "AI response", "thoughts": "AI thoughts"}
    return {"reply": "AI response"}