from http.client import responses

from fastapi import APIRouter
from models.Query import Query, AttachmentEnum
from util.ai_utils import query_llm

router = APIRouter(prefix="/query", tags=["ai"])

@router.get("/")
async def query_get():
    """
    Handles the asynchronous GET request to query data and responds based on the 
    context of the operation. Executes conditional behavior to either return a 
    model-dumped query result or a specified response message.

    :return: The model-dumped representation of the query result if in development 
             mode, otherwise a dictionary containing a specific response message.
    :rtype: dict

    :raises: Logs exceptions during the execution process.
    """
    dev = True
    try:
        if dev:
            _query = Query()
            return _query.model_dump()
        else:
            return {"response": "These are not the droids you are looking for"}
    except Exception as e:
        print(e)

@router.post("/")
async def query_post(query: Query):
    """
    Handles POST requests to process a query.

    This function processes a query object by invoking the `query_llm` function,
    which interacts with the specified LLM to generate a response based on the
    provided query details. The generation can optionally display intermediate
    thought processes, depending on the `show_thoughts` attribute.

    :param query: Instance of the Query class containing the content, LLM, model,
                  and optional settings for thought display.
    :return: The response generated by the LLM based on the given query details.
    :rtype: Depends on the implementation of `query_llm` function.
    """
    return await query_llm(
        query=query.content,
        llm=query.llm,
        model=query.model,
        show_thoughts=query.show_thoughts
    )